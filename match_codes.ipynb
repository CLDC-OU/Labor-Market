{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depending on the current year, we want a specified 10 year range to report data on\n",
    "years = [datetime.datetime.now().year - 2, datetime.datetime.now().year + 8]\n",
    "\n",
    "# Load up config\n",
    "with open('config.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Define paths dict\n",
    "paths_dict = data[\"file_paths\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_50_input = paths_dict[\"HOT_50_INPUT\"][\"path\"]\n",
    "hot_50_output = paths_dict[\"HOT_50_OUTPUT\"][\"path\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python hot_50_pdf_scraper.py -i {hot_50_input} -c {hot_50_output}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot50 = pd.read_csv(paths_dict[\"HOT_50_OUTPUT\"][\"path\"])\n",
    "valid_majors = pd.read_csv(paths_dict[\"MAJORS\"][\"path\"], dtype=str)\n",
    "crosswalk = pd.read_excel(paths_dict[\"CIP_TO_SOC_CROSSWALK\"][\"path\"], dtype=str)\n",
    "mismatched_codes = pd.read_csv(paths_dict[\"MISMATCHED_LIGHTCAST_CODES\"][\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match CIP to SOC with OU Majors so we can obtain SOCS for Majors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Codes and titles have years associated with them, we want them to be generalized so we don't have to rename the columns every time\n",
    "## we want to run the scripting\n",
    "CIP_CODE_TAG = crosswalk.columns[0]\n",
    "CIP_TITLE = crosswalk.columns[1]\n",
    "SOC_CODE_TAG = crosswalk.columns[2]\n",
    "SOC_TITLE = crosswalk.columns[3]\n",
    "\n",
    "crosswalk = crosswalk.rename(columns={CIP_CODE_TAG: \"CIP_CODE_TAG\", CIP_TITLE: \"CIP_TITLE\",\n",
    "                          SOC_CODE_TAG: \"SOC_CODE_TAG\", SOC_TITLE: \"SOC_TITLE\"})\n",
    "\n",
    "# We want a \"hot job\" label for those on the hot jobs list\n",
    "hot50[\"Hot Tag\"] = \"T\"\n",
    "\n",
    "# Get crosswalk ready for merge\n",
    "crosswalk[\"CIP_CODE_TAG\"] = crosswalk[\"CIP_CODE_TAG\"].str.replace(\".\", \"-\")\n",
    "\n",
    "# Get valid majors ready for merge\n",
    "valid_majors[\"stvmajr_cipc_code\"] = valid_majors[\"stvmajr_cipc_code\"].str.replace('.0', '')\n",
    "valid_majors[\"stvmajr_cipc_code\"] = valid_majors[\"stvmajr_cipc_code\"].str[:-4] + '-' + valid_majors[\"stvmajr_cipc_code\"].str[-4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge together Oakland Majors with Crosswalk information and include a tag if it's a part of the hot jobs\n",
    "ou_majors_with_soc = pd.merge(valid_majors, crosswalk, left_on=[\"stvmajr_cipc_code\"], right_on=[\"CIP_CODE_TAG\"], how=\"left\")\n",
    "ou_majors_with_soc = pd.merge(ou_majors_with_soc, hot50, left_on=[\"SOC_TITLE\"], right_on=[\"Profession\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We only care about specific columns and those that have SOC codes\n",
    "ou_majors_with_soc = ou_majors_with_soc.loc[(ou_majors_with_soc[\"SOC_CODE_TAG\"].notnull()), [\"stvmajr_code\", \"stvmajr_desc\", \"CIP_CODE_TAG\", \"CIP_TITLE\", \"SOC_CODE_TAG\", \"SOC_TITLE\", \"Hot Tag\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab distinct code list\n",
    "codes = ou_majors_with_soc[\"SOC_CODE_TAG\"].dropna().drop_duplicates().to_list()\n",
    "\n",
    "# Write codes into a txt file\n",
    "with open(paths_dict[\"SOC_CODES_FOR_ONET\"][\"path\"], \"w\") as file:\n",
    "    file.writelines(code + '\\n' for code in codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain ONET data for each of our SOC codes vs ONET API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../ONET/ONET_API.py < Inputs/SOCcodes.txt > Outputs/ONET.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning ONET Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the ONET json dictionary\n",
    "with open(f\"Outputs/ONET.json\", \"r\") as file:\n",
    "    ONET_data = json.load(file)\n",
    "\n",
    "# Move dictionary to a dataframe where the different SOCs are rows\n",
    "ONET_df = pd.DataFrame.from_dict(ONET_data, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand \"results\" columns so they are columns in the df\n",
    "ONET_df = ONET_df[\"results\"].apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick function for cleaning one of the results columns\n",
    "def get_MI_quotient(row):\n",
    "    try:\n",
    "        for category in row.keys():\n",
    "            for state in row[category]['state']:\n",
    "                if state[\"name\"] == \"Michigan\":\n",
    "                    return state[\"location_quotient\"]  \n",
    "        return None\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take desired values out of the dictionaries in their current columns\n",
    "ONET_df[\"abilities\"] = ONET_df[\"abilities\"].apply(lambda x: ', '.join(group['title']['name'] for group in x['group']) if isinstance(x, dict) else None)\n",
    "ONET_df[\"aliases\"] = ONET_df[\"career\"].apply(lambda x: ', '.join(x[\"also_called\"][\"title\"]) if isinstance(x, dict) and \"also_called\" in x and \"title\" in x[\"also_called\"] else None)\n",
    "ONET_df[\"task\"] = ONET_df[\"career\"].apply(lambda x: x[\"what_they_do\"] if isinstance(x, dict) and \"what_they_do\" in x else None)\n",
    "ONET_df[\"knowledge\"] = ONET_df[\"knowledge\"].apply(lambda x: ', '.join(group['title']['name'] for group in x['group']) if isinstance(x, dict) else None)\n",
    "ONET_df[\"personality_type\"] = ONET_df[\"personality\"].apply(lambda x: x[\"top_interest\"][\"title\"])\n",
    "ONET_df[\"interests\"] = ONET_df[\"personality\"].apply(lambda x: x[\"top_interest\"][\"description\"])\n",
    "ONET_df[\"skills\"] = ONET_df[\"skills\"].apply(lambda x: ', '.join(group['title']['name'] for group in x['group']) if isinstance(x, dict) else None)\n",
    "ONET_df[\"technology\"] = ONET_df[\"technology\"].apply(lambda x: ', '.join(group['title']['name'] for group in x['category']) if isinstance(x, dict) else None)\n",
    "ONET_df[\"where_do_they_work\"] = ONET_df[\"where_do_they_work\"].apply(lambda x: ', '.join(f\"{group['title']} ({group['percent_employed']}%)\" for group in x[\"industry\"]) if isinstance(x, dict) else None)\n",
    "ONET_df[\"MI_to_rel_avg\"] = ONET_df[\"check_out_my_state\"].apply(lambda x: get_MI_quotient(x))\n",
    "ONET_df[\"education\"] = ONET_df[\"education\"].apply(\n",
    "    lambda x: ', '.join([word.title() for word in x[\"education_usually_needed\"][\"category\"]]) \n",
    "    if \"education_usually_needed\" in x and x[\"education_usually_needed\"].get(\"category\") else ''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter specific ONET columns\n",
    "ONET_df = ONET_df.loc[:, [\"abilities\", \"aliases\", \"task\", \"knowledge\", \"personality_type\", \"interests\", \"skills\", \"technology\", \"where_do_they_work\", \"MI_to_rel_avg\", \"education\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set SOC to a column and remove index\n",
    "ONET_df.index.names = [\"SOC\"]\n",
    "ONET_df.reset_index(inplace=True)\n",
    "\n",
    "# Remove \".00\" from SOC Codes\n",
    "ONET_df[\"SOC\"] = ONET_df[\"SOC\"].str[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to account for codes that were incorrect in lightcast, so we match with the mismatches and change them to update to our correct classifications\n",
    "ONET_df = pd.merge(ONET_df, mismatched_codes, left_on=\"SOC\", right_on=\"Crosswalk\", how=\"left\")\n",
    "ONET_df[\"SOC\"] = np.where(ONET_df[\"OEWS\"].notnull(), ONET_df[\"OEWS\"], ONET_df[\"SOC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONET_df.to_excel(paths_dict[\"ONET_INFO_FOR_SOCS\"][\"path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching ONET Data and LightCast Data to OU Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in lightcast data\n",
    "lightcast = pd.read_excel(paths_dict[\"LIGHTCAST_OCCUPATION_REPORT\"][\"path\"], sheet_name=\"Occs\")\n",
    "\n",
    "# Merge ONET and lightcast data together on SOC code\n",
    "lightcast_code_matched = pd.merge(ONET_df, lightcast, on=[\"SOC\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also want to account for codes that were incorrect in lightcast, so we match with the mismatches and change them to update to our correct classifications\n",
    "ou_majors_with_soc = pd.merge(ou_majors_with_soc, mismatched_codes, left_on=\"SOC_CODE_TAG\", right_on=\"Crosswalk\", how=\"left\")\n",
    "ou_majors_with_soc[\"SOC_CODE_TAG\"] = np.where(ou_majors_with_soc[\"OEWS\"].notnull(), ou_majors_with_soc[\"OEWS\"], ou_majors_with_soc[\"SOC_CODE_TAG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with OU Data\n",
    "lightcast_ou_matched = pd.merge(ou_majors_with_soc, lightcast_code_matched, right_on=[\"SOC\"], left_on=[\"SOC_CODE_TAG\"], how=\"left\")\n",
    "\n",
    "lightcast_ou_matched = lightcast_ou_matched.drop_duplicates(subset=[\"stvmajr_desc\", \"SOC_TITLE\"], keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df for Jobs Increase visualization\n",
    "ou_all_data_jobs = lightcast_ou_matched.melt(id_vars=[\"CIP_CODE_TAG\", \"stvmajr_desc\", \"SOC_TITLE\"], value_vars=[f\"{years[0]} Jobs\", f\"{years[1]} Jobs\"], var_name=\"Jobs Year\", value_name=\"Jobs\")\n",
    "ou_all_data_wages = lightcast_ou_matched.melt(id_vars=[\"CIP_CODE_TAG\", \"stvmajr_desc\", \"SOC_TITLE\"], value_vars=[\"Pct. 10 Annual Earnings\", \"Pct. 25 Annual Earnings\", \"Median Annual Earnings\", \"Pct. 75 Annual Earnings\", \"Pct. 90 Annual Earnings\"], var_name=\"PCT Category\", value_name=\"Earnings\")\n",
    "ou_all_data_demographics = lightcast_ou_matched.melt(id_vars=[\"CIP_CODE_TAG\", \"stvmajr_desc\", \"SOC_TITLE\"], value_vars=[\"Current Year Total Diversity % of Occupation\", \"Current Year White % of Occupation\", \"Current Year Males % of Occupation\", \"Current Year Females % of Occupation\", \"Current Year Age 14-18 % of Occupation\", \"Current Year Age 19-21 % of Occupation\", \"Current Year Age 22-24 % of Occupation\", \"Current Year Age 25-34 % of Occupation\", \"Current Year Age 35-44 % of Occupation\", \"Current Year Age 45-54 % of Occupation\", \"Current Year Age 45-54 % of Occupation\", \"Current Year Age 55-64 % of Occupation\", \"Current Year Age 65+ % of Occupation\"], var_name=\"Demographic\", value_name=\"PCT Demographic\")\n",
    "\n",
    "# Change Variable Name Values to be Usable in Looker\n",
    "ou_all_data_jobs[\"Jobs Year\"] = ou_all_data_jobs[\"Jobs Year\"].str[:4]\n",
    "\n",
    "# Lightcast puts filtered year columns in the df, we want to rename them to be generalizable\n",
    "lightcast_ou_matched = lightcast_ou_matched.rename(columns={f\"{years[0]} Jobs\": \"Beginning Range Jobs\", f\"{years[1]} Jobs\": \"End Range Jobs\", \n",
    "                                                            f\"{years[0]} - {years[1]} Change\": \"Jobs Range Change\", f\"{years[0]} - {years[1]} % Change\": \"Jobs Range PCT Change\",\n",
    "                                                            f\"{years[0]} - {years[1]} Openings\": \"Jobs Range Openings\"})\n",
    "\n",
    "\n",
    "\n",
    "ou_all_data_wages.loc[ou_all_data_wages[\"PCT Category\"] == \"Median Annual Earnings\", \"PCT Category\"] = \"Pct. 50 Annual Earnings\"\n",
    "ou_all_data_wages[\"PCT Category\"] = ou_all_data_wages[\"PCT Category\"].str[5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop dups\n",
    "ou_all_data_jobs = ou_all_data_jobs.drop_duplicates(keep=\"first\")\n",
    "ou_all_data_wages = ou_all_data_wages.drop_duplicates(keep=\"first\")\n",
    "ou_all_data_demographics = ou_all_data_demographics.drop_duplicates(keep=\"first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dfs\n",
    "lightcast_ou_matched.to_excel(paths_dict[\"PROGRAM_STATS\"][\"path\"], index=False)\n",
    "ou_all_data_jobs.to_excel(paths_dict[\"JOB_COUNTS\"][\"path\"], index=False)\n",
    "ou_all_data_wages.to_excel(paths_dict[\"JOB_WAGES\"][\"path\"], index=False)\n",
    "ou_all_data_demographics.to_excel(paths_dict[\"JOB_DEMOGRAPHICS\"][\"path\"], index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take Manual Job Posting Information from Lightcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = lightcast_ou_matched[\"SOC\"].dropna().drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "gen_path = paths_dict[\"GOOGLE_FOLDER_MI_HIRING\"][\"path\"]\n",
    "dataframes = []\n",
    "\n",
    "for code in codes:\n",
    "    new_path = os.path.join(gen_path, f\"{code}.csv\")\n",
    "    try:\n",
    "        tmp = pd.read_csv(new_path).iloc[0:50, :]\n",
    "    except:\n",
    "        continue\n",
    "    tmp[\"SOC\"] = code\n",
    "    dataframes.append(tmp)\n",
    "\n",
    "agg = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = agg[agg[\"Latest 365 Days Unique Postings\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg.to_csv(paths_dict[\"LIGHTCAST_MI_JOBS\"][\"path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cldc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
